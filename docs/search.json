[
  {
    "objectID": "publications/index.html",
    "href": "publications/index.html",
    "title": "Jess Alexander",
    "section": "",
    "text": "2024\n\n\nAlexander, J. M. and Buzzell, G. A. (2024). Emotional Context and Predictability in Naturalistic Reading Aloud. Emotion. | [DOI] | [preprint] | [data+code] | [social ðŸ§µ]"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jess Alexander",
    "section": "",
    "text": "I am a neurolinguist whose research lies at the intersection of acoustic phonetics, signal processing, and the neurobiology of auditory speech perception.\nRaised in the San Francisco Bay Area, I received a bachelor degree in linguistics from Boston University. This led to a 17-year career in the translation industry, first as a freelance translator and ultimately as an operational executive for an agency focused on life sciences translations. At this agency, I managed a team of project managers who supported medical device and biotechnology innovators in bringing new products to international markets. In 2021, I pivoted back to research, serving as the lab manager for an electrophysiology laboratory at Florida International University. I started my doctoral degree at the University of Texas at Austin in 2023.\nOutside the lab, I love food, travel, and running (modestly) long distances.\nI also curate a list of open datasets for neurolinguistics.\n\n\nNatural human language is often conceptualized as serving a fundamental role of social communication, be this in transferring thoughts and ideas between individuals or groups, or in similarly establishing connections that forge friendships, cultures, and communities. Prosodyâ€“the intonation, rhythm, and timbre of speechâ€“is vital to such social communication, manifesting meaningful effects on interindividual collaboration and negotiation. My research explores the perceptual power and cognitive costs of prosodic signals, particularly speech whose multi-faceted acoustics offer to the listener cues about the emotional state of the speaker. Which features does the listener use to intuit, in the flash of an eye, that their interlocutor is happy, bored, or irritated? How do these emotional tones of voice impact the cognitive and neural function of the listener? I investigate these questions using statistical modeling of human behavior, as well as computational models of the nonlinear dynamics of the electrical activity of the human brain (EEG).\nMy research seeks to broaden our understanding of the cognitive consequences of emotional communication with a view toward improving assistive hearing technologies, enhancing human-computer interactions, and creating healthier acoustic spaces for learning, work, and play.\n\n\n\n2025-02-13 Led a workshop on data visualization. 2024-11-19 Presented a flashtalk at ASA187 on the benefits of happy and angry prosody for speech & emotion recognition. 2024-10-15 Honored to be selected as an inaugural fellow of the UT Austin Scholars Lab. 2024-06-30 Launched this website!"
  },
  {
    "objectID": "index.html#research",
    "href": "index.html#research",
    "title": "Jess Alexander",
    "section": "",
    "text": "Natural human language is often conceptualized as serving a fundamental role of social communication, be this in transferring thoughts and ideas between individuals or groups, or in similarly establishing connections that forge friendships, cultures, and communities. Prosodyâ€“the intonation, rhythm, and timbre of speechâ€“is vital to such social communication, manifesting meaningful effects on interindividual collaboration and negotiation. My research explores the perceptual power and cognitive costs of prosodic signals, particularly speech whose multi-faceted acoustics offer to the listener cues about the emotional state of the speaker. Which features does the listener use to intuit, in the flash of an eye, that their interlocutor is happy, bored, or irritated? How do these emotional tones of voice impact the cognitive and neural function of the listener? I investigate these questions using statistical modeling of human behavior, as well as computational models of the nonlinear dynamics of the electrical activity of the human brain (EEG).\nMy research seeks to broaden our understanding of the cognitive consequences of emotional communication with a view toward improving assistive hearing technologies, enhancing human-computer interactions, and creating healthier acoustic spaces for learning, work, and play."
  },
  {
    "objectID": "index.html#news",
    "href": "index.html#news",
    "title": "Jess Alexander",
    "section": "",
    "text": "2025-02-13 Led a workshop on data visualization. 2024-11-19 Presented a flashtalk at ASA187 on the benefits of happy and angry prosody for speech & emotion recognition. 2024-10-15 Honored to be selected as an inaugural fellow of the UT Austin Scholars Lab. 2024-06-30 Launched this website!"
  }
]