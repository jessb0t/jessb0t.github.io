---
title: "Jess Alexander"
image: "avatar.jpg"
image-alt: "close-up photo of Jess"
about:
  template: trestles
  links:
    - icon: github
      url: "https://github.com/jessb0t"
    - icon: linkedin
      url: "https://www.linkedin.com/in/jessmalexander/"
    - text: BSky
      url: "https://bsky.app/profile/je55bot.bsky.social"
    - icon: envelope
      url: "mailto:jessica.alexander@utexas.edu"
    - text: CV
      url: "cv.pdf"
comments: false
---
::: {.column-page}
I am a neurolinguist whose research lies at the intersection of acoustic phonetics, signal processing, and the neurobiology of auditory speech perception.

Raised in the San Francisco Bay Area, I received a bachelor degree in linguistics from Boston University. This led to a 17-year career in the translation industry, first as a freelance translator and ultimately as an operational executive for an agency focused on life sciences translations. At this agency, I managed a team of project managers who supported medical device and biotechnology innovators in bringing new products to international markets. In 2021, I pivoted back to research, serving as the lab manager for an electrophysiology laboratory at Florida International University. I started my doctoral degree at the University of Texas at Austin in 2023.

Outside the lab, I love food, travel, and running (modestly) long distances.

I also curate a list of [open datasets for neurolinguistics](https://jessb0t.github.io/neuroling-resources/).

## Research
Natural human language serves a fundamental role in social communication, both in transferring thoughts and ideas between individuals or groups, as well as in establishing emotional connections that forge friendships, cultures, and communities. Prosody–the intonation, rhythm, and timbre of speech–is vital to such social communication, and tone of voice can dramatically impact interindividual collaboration and negotiation. My research explores the perceptual power and cognitive costs of prosodic signals, particularly speech whose multi-faceted acoustics offer to the listener cues about the emotional state of the speaker. Which features does the listener use to intuit, in the flash of an eye, that their interlocutor is happy, bored, or irritated? How do these emotional tones of voice impact the cognitive and neural function of the listener? I investigate these questions using statistical modeling of human behavior, as well as computational models of the nonlinear dynamics of the electrical activity of the human brain (EEG).

My research seeks to broaden our understanding of the cognitive consequences of emotional communication with a view toward improving assistive hearing technologies, enhancing human-computer interactions, and creating healthier acoustic spaces for learning, work, and play.

## News
<span class="badge bg-success">2025-02-13</span> Led a  [workshop](https://guides.lib.utexas.edu/data-and-donuts) on data visualization.<br>
<span class="badge bg-success">2024-11-19</span> Presented a flashtalk at [ASA187](https://acousticalsociety.org/) on the benefits of happy and angry prosody for speech & emotion recognition.<br>
<span class="badge bg-success">2024-10-15</span> Honored to be selected as an inaugural fellow of the UT Austin Scholars Lab.<br>
<span class="badge bg-success">2024-06-30</span> Launched this website!
:::